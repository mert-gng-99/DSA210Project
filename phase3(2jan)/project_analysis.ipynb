{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Machine Learning Analysis\n",
        "This notebook contains the machine learning analysis for the project.\n",
        "It covers:\n",
        "1. Regression\n",
        "2. Classification\n",
        "3. Unsupervised Learning (Clustering)\n",
        "4. Time Series Analysis\n",
        "5. Dimensionality Reduction (PCA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Required Machine Learning Libraries (from slides)\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, confusion_matrix\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.tsa.arima.model import ARIMA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. DATA PREPARATION\n",
        "# =================\n",
        "print(\"Loading and cleaning data...\")\n",
        "# Load data\n",
        "gdp_df = pd.read_csv('API_NY.GDP.PCAP.PP.KD_DS2_en_csv_v2_130128.csv', skiprows=4)\n",
        "co2_df = pd.read_csv('owid-co2-data (1).csv')\n",
        "\n",
        "# Organize GDP data (Years to rows)\n",
        "gdp_clean = gdp_df.drop(columns=['Indicator Name', 'Indicator Code', 'Unnamed: 69'], errors='ignore')\n",
        "gdp_long = gdp_clean.melt(id_vars=['Country Name', 'Country Code'], \n",
        "                          var_name='year', \n",
        "                          value_name='gdp_per_capita')\n",
        "gdp_long['year'] = pd.to_numeric(gdp_long['year'], errors='coerce')\n",
        "gdp_long = gdp_long.dropna(subset=['year', 'gdp_per_capita'])\n",
        "gdp_long['year'] = gdp_long['year'].astype(int)\n",
        "\n",
        "# Organize CO2 data\n",
        "co2_clean = co2_df[['iso_code', 'country', 'year', 'co2_per_capita', 'population']]\n",
        "co2_clean = co2_clean.dropna(subset=['co2_per_capita', 'iso_code'])\n",
        "\n",
        "# Merge two tables\n",
        "data = pd.merge(gdp_long, co2_clean, left_on=['Country Code', 'year'], right_on=['iso_code', 'year'])\n",
        "data = data.dropna() # Drop rows with missing data\n",
        "print(f\"Data ready. Total Rows: {data.shape[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. REGRESSION ANALYSIS (Predicting CO2) - (Week 8 & 9)\n",
        "# ====================================================\n",
        "print(\"\\n--- 2. Regression Analysis (Week 8 & 9) ---\")\n",
        "# Goal: Predict CO2 using GDP and Population\n",
        "X_reg = data[['gdp_per_capita', 'population', 'year']]\n",
        "y_reg = data['co2_per_capita']\n",
        "\n",
        "# Split into Training and Test sets (80% Train, 20% Test)\n",
        "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_reg, y_reg, test_size=0.2, random_state=42)\n",
        "\n",
        "# Model A: Linear Regression (Week 8)\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X_train_reg, y_train_reg)\n",
        "y_pred_lin = lin_reg.predict(X_test_reg)\n",
        "print(f\"Linear Regression R2 Score: {r2_score(y_test_reg, y_pred_lin):.4f}\")\n",
        "\n",
        "# Model B: Polynomial Regression (For EKC Hypothesis) (Week 8)\n",
        "poly = PolynomialFeatures(degree=2)\n",
        "# We test the relationship by checking the square of GDP\n",
        "X_poly_train = poly.fit_transform(X_train_reg[['gdp_per_capita']]) \n",
        "X_poly_test = poly.transform(X_test_reg[['gdp_per_capita']])\n",
        "poly_reg = LinearRegression()\n",
        "poly_reg.fit(X_poly_train, y_train_reg)\n",
        "y_pred_poly = poly_reg.predict(X_poly_test)\n",
        "print(f\"Polynomial Regression (EKC) R2 Score: {r2_score(y_test_reg, y_pred_poly):.4f}\")\n",
        "\n",
        "# Model C: Random Forest Regressor (Week 9)\n",
        "rf_reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_reg.fit(X_train_reg, y_train_reg)\n",
        "y_pred_rf = rf_reg.predict(X_test_reg)\n",
        "print(f\"Random Forest Regressor R2 Score: {r2_score(y_test_reg, y_pred_rf):.4f}\")\n",
        "\n",
        "# Visualize Regression Results\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.scatter(y_test_reg, y_pred_rf, alpha=0.5, color='green', label='Predictions')\n",
        "plt.plot([0, y_test_reg.max()], [0, y_test_reg.max()], 'r--', label='Perfect Prediction')\n",
        "plt.xlabel('Actual CO2')\n",
        "plt.ylabel('Predicted CO2 (Random Forest)')\n",
        "plt.title('Regression Results: Actual vs Predicted CO2 Emissions')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. CLASSIFICATION ANALYSIS (Week 8 & 9)\n",
        "# ================================================\n",
        "print(\"\\n--- 3. Classification Analysis (Week 8 & 9) ---\")\n",
        "# Goal: Is the country \"High Emission\"? (Above the median?)\n",
        "threshold = data['co2_per_capita'].median()\n",
        "data['is_high_emitter'] = (data['co2_per_capita'] > threshold).astype(int)\n",
        "\n",
        "X_clf = data[['gdp_per_capita', 'population']]\n",
        "y_clf = data['is_high_emitter']\n",
        "\n",
        "X_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(X_clf, y_clf, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale data (Required for Logistic Regression and KNN)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_clf)\n",
        "X_test_scaled = scaler.transform(X_test_clf)\n",
        "\n",
        "# Model A: Logistic Regression (Week 8)\n",
        "log_reg = LogisticRegression()\n",
        "log_reg.fit(X_train_scaled, y_train_clf)\n",
        "print(f\"Logistic Regression Accuracy: {log_reg.score(X_test_scaled, y_test_clf):.4f}\")\n",
        "\n",
        "# Model B: KNN (K-Nearest Neighbors) (Week 9)\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train_scaled, y_train_clf)\n",
        "print(f\"KNN Accuracy: {knn.score(X_test_scaled, y_test_clf):.4f}\")\n",
        "\n",
        "# Model C: Random Forest Classifier (Week 9)\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_clf.fit(X_train_clf, y_train_clf)\n",
        "print(f\"Random Forest Classifier Accuracy: {rf_clf.score(X_test_clf, y_test_clf):.4f}\")\n",
        "\n",
        "# Visualize Confusion Matrix\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(confusion_matrix(y_test_clf, rf_clf.predict(X_test_clf)), annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Confusion Matrix (Random Forest Classification)')\n",
        "plt.ylabel('Actual Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. UNSUPERVISED LEARNING (Clustering) - (Week 10)\n",
        "# ===============================================\n",
        "print(\"\\n--- 4. Unsupervised Learning (Week 10) ---\")\n",
        "# Group countries using 2019 data\n",
        "data_2019 = data[data['year'] == 2019].copy()\n",
        "X_cluster = data_2019[['gdp_per_capita', 'co2_per_capita']]\n",
        "\n",
        "# Scaling (Important for Clustering)\n",
        "scaler_cluster = StandardScaler()\n",
        "X_cluster_scaled = scaler_cluster.fit_transform(X_cluster)\n",
        "\n",
        "# K-Means Algorithm\n",
        "kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
        "data_2019['Cluster'] = kmeans.fit_predict(X_cluster_scaled)\n",
        "\n",
        "# Visualize Clusters\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(data=data_2019, x='gdp_per_capita', y='co2_per_capita', hue='Cluster', palette='viridis', s=100)\n",
        "plt.xscale('log') # Logarithmic scale shows clearer results\n",
        "plt.yscale('log')\n",
        "plt.title('K-Means Clustering: Country Groups based on GDP & CO2')\n",
        "plt.xlabel('GDP per Capita (Log Scale)')\n",
        "plt.ylabel('CO2 per Capita (Log Scale)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. TIME SERIES FORECASTING (Week 13)\n",
        "# =================================================\n",
        "print(\"\\n--- 5. Time Series Analysis (Week 13) ---\")\n",
        "# Predict CO2 for USA for the next 5 years\n",
        "usa_data = data[data['Country Code'] == 'USA'].sort_values('year')\n",
        "# Set year as index\n",
        "ts_data = usa_data.set_index('year')['co2_per_capita']\n",
        "\n",
        "# ARIMA Model (Autoregressive Integrated Moving Average)\n",
        "model_arima = ARIMA(ts_data, order=(1,1,1)) # Simple (1,1,1) model\n",
        "model_fit = model_arima.fit()\n",
        "\n",
        "# Forecast next 5 years\n",
        "forecast = model_fit.forecast(steps=5)\n",
        "print(\"USA CO2 Forecast (Next 5 Years):\")\n",
        "print(forecast)\n",
        "\n",
        "# Visualize Forecast\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(ts_data.index, ts_data.values, label='Historical Data (1990-2020)')\n",
        "plt.plot(forecast.index, forecast.values, label='Forecast (Next 5 Years)', color='red', linestyle='--')\n",
        "plt.title('Time Series Forecasting: USA CO2 Emissions')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('CO2 per Capita')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6. DIMENSIONALITY REDUCTION (PCA)\n",
        "# =================================\n",
        "print(\"\\n--- 6. Principal Component Analysis (PCA) ---\")\n",
        "# Use the same 2019 data\n",
        "X_pca = data_2019[['gdp_per_capita', 'population', 'co2_per_capita']]\n",
        "\n",
        "# Scale data\n",
        "scaler_pca = StandardScaler()\n",
        "X_pca_scaled = scaler_pca.fit_transform(X_pca)\n",
        "\n",
        "# Apply PCA (Reduce to 2 components)\n",
        "pca = PCA(n_components=2)\n",
        "principal_components = pca.fit_transform(X_pca_scaled)\n",
        "\n",
        "# Create DataFrame for visualization\n",
        "pca_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'])\n",
        "# Use clusters from previous step if available, otherwise just plot\n",
        "if 'Cluster' in data_2019.columns:\n",
        "    pca_df['Cluster'] = data_2019['Cluster'].values\n",
        "    hue_col = 'Cluster'\n",
        "else:\n",
        "    hue_col = None\n",
        "\n",
        "# Visualize PCA\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(data=pca_df, x='PC1', y='PC2', hue=hue_col, palette='viridis', s=100)\n",
        "plt.title('PCA: 2D Projection of Country Data')\n",
        "plt.xlabel(f'Principal Component 1 ({pca.explained_variance_ratio_[0]:.2f} variance)')\n",
        "plt.ylabel(f'Principal Component 2 ({pca.explained_variance_ratio_[1]:.2f} variance)')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}